{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import datetime\n",
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "from pathlib import Path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\joaoa\\.conda\\envs\\torch\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import timm\n",
    "# assert timm.__version__ == \"0.3.2\"  # version check\n",
    "import timm.optim.optim_factory as optim_factory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import util.misc as misc\n",
    "from util.misc import NativeScalerWithGradNormCount as NativeScaler\n",
    "\n",
    "import models_mae\n",
    "\n",
    "from engine_pretrain import train_one_epoch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_args_parser():\n",
    "    # Create an argument parser named 'parser'\n",
    "    parser = argparse.ArgumentParser('MAE Pre-training', add_help=False)\n",
    "    # 'MAE Pre-training' is the description that will appear in the help message when the script is run\n",
    "    # 'add_help=False' disables the default help option (-h or --help) to allow hierarchical argument structure\n",
    "\n",
    "    # Define various arguments with their details using parser.add_argument()\n",
    "    parser.add_argument('--batch_size', default=64, type=int,\n",
    "                        help='Batch size per GPU (effective batch size is batch_size * accum_iter * # gpus')\n",
    "    \n",
    "    parser.add_argument('--epochs', default=400, type=int)\n",
    "    \n",
    "    parser.add_argument('--accum_iter', default=1, type=int,\n",
    "                        help='Accumulate gradient iterations (for increasing effective batch size under memory constraints)')\n",
    "\n",
    "    # Model parameters\n",
    "    parser.add_argument('--model', default='mae_vit_large_patch16', type=str, metavar='MODEL',\n",
    "                        help='Name of model to train')\n",
    "\n",
    "    parser.add_argument('--input_size', default=224, type=int,\n",
    "                        help='Image input size')\n",
    "\n",
    "    parser.add_argument('--mask_ratio', default=0.75, type=float,\n",
    "                        help='Masking ratio (percentage of removed patches).')\n",
    "\n",
    "    parser.add_argument('--norm_pix_loss', action='store_true',\n",
    "                        help='Use normalized pixels (per patch) as targets for computing loss')\n",
    "    parser.set_defaults(norm_pix_loss=False)  # Set default value for 'norm_pix_loss' as False\n",
    "\n",
    "    # Optimizer parameters\n",
    "    parser.add_argument('--weight_decay', type=float, default=0.05,\n",
    "                        help='Weight decay (default: 0.05)')\n",
    "\n",
    "    parser.add_argument('--lr', type=float, default=None, metavar='LR',\n",
    "                        help='Learning rate (absolute lr)')\n",
    "    \n",
    "    parser.add_argument('--blr', type=float, default=1e-3, metavar='LR',\n",
    "                        help='Base learning rate: absolute_lr = base_lr * total_batch_size / 256')\n",
    "    \n",
    "    parser.add_argument('--min_lr', type=float, default=0., metavar='LR',\n",
    "                        help='Lower LR bound for cyclic schedulers that hit 0')\n",
    "\n",
    "    parser.add_argument('--warmup_epochs', type=int, default=40, metavar='N',\n",
    "                        help='Epochs to warm up LR')\n",
    "\n",
    "    # Dataset parameters\n",
    "    parser.add_argument('--data_path', default='/datasets01/imagenet_full_size/061417/', type=str,\n",
    "                        help='Dataset path')\n",
    "\n",
    "    parser.add_argument('--output_dir', default='./output_dir',\n",
    "                        help='Path to save results, empty for no saving')\n",
    "    \n",
    "    parser.add_argument('--log_dir', default='./output_dir',\n",
    "                        help='Path to TensorBoard log')\n",
    "    \n",
    "    parser.add_argument('--device', default='cuda',\n",
    "                        help='Device to use for training / testing')\n",
    "    \n",
    "    parser.add_argument('--seed', default=0, type=int)\n",
    "    \n",
    "    parser.add_argument('--resume', default='',\n",
    "                        help='Resume from checkpoint')\n",
    "\n",
    "    parser.add_argument('--start_epoch', default=0, type=int, metavar='N',\n",
    "                        help='Start epoch')\n",
    "    \n",
    "    parser.add_argument('--num_workers', default=10, type=int)\n",
    "    \n",
    "    parser.add_argument('--pin_mem', action='store_true',\n",
    "                        help='Pin CPU memory in DataLoader for more efficient (sometimes) transfer to GPU.')\n",
    "    parser.add_argument('--no_pin_mem', action='store_false', dest='pin_mem')\n",
    "    parser.set_defaults(pin_mem=True)  # Set default value for 'pin_mem' as True\n",
    "\n",
    "    # Distributed training parameters\n",
    "    parser.add_argument('--world_size', default=1, type=int,\n",
    "                        help='Number of distributed processes')\n",
    "    \n",
    "    parser.add_argument('--local_rank', default=-1, type=int)\n",
    "    \n",
    "    parser.add_argument('--dist_on_itp', action='store_true')\n",
    "    \n",
    "    parser.add_argument('--dist_url', default='env://',\n",
    "                        help='URL used to set up distributed training')\n",
    "\n",
    "    return parser  # Return the fully configured argument parser\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
